{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build a language detector model\n",
    "\n",
    "The goal of this exercise is to train a linear classifier on text features\n",
    "that represent sequences of up to 3 consecutive characters so as to be\n",
    "recognize natural languages by using the frequencies of short character\n",
    "sequences as 'fingerprints'.\n",
    "\n",
    "\"\"\"\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "# License: Simplified BSD\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# The training data folder must be passed as first argument\n",
    "languages_data_folder = 'data/languages/paragraphs/'\n",
    "dataset = load_files(languages_data_folder)\n",
    "\n",
    "# Split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer that splits strings into sequence of 1 to 3\n",
    "# characters instead of word tokens\n",
    "split13 = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer / classifier pipeline using the previous analyzer\n",
    "# the pipeline instance should stored in a variable named clf\n",
    "clf = Pipeline([('vec', split13), ('clf', Perceptron(tol=1e-8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ..._jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=1e-08, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Fit the pipeline on the training set\n",
    "clf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         ar       1.00      1.00      1.00        12\n",
      "         de       0.99      1.00      0.99        91\n",
      "         en       1.00      1.00      1.00        85\n",
      "         es       1.00      0.96      0.98        55\n",
      "         fr       1.00      1.00      1.00        62\n",
      "         it       1.00      1.00      1.00        43\n",
      "         ja       1.00      1.00      1.00        29\n",
      "         nl       1.00      0.95      0.98        22\n",
      "         pl       1.00      1.00      1.00        17\n",
      "         pt       0.96      1.00      0.98        44\n",
      "         ru       1.00      1.00      1.00        30\n",
      "\n",
      "avg / total       0.99      0.99      0.99       490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 91  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 85  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 53  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 43  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 29  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 17  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 44  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed1fcc16d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(cm, cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"This is a language detection test.\" is \"en\"\n",
      "The language of \"Ceci est un test de détection de la langue.\" is \"fr\"\n",
      "The language of \"Dies ist ein Test, um die Sprache zu erkennen.\" is \"de\"\n"
     ]
    }
   ],
   "source": [
    "# Predict the result on some short new sentences:\n",
    "sentences = [\n",
    "    u'This is a language detection test.',\n",
    "    u'Ceci est un test de d\\xe9tection de la langue.',\n",
    "    u'Dies ist ein Test, um die Sprache zu erkennen.',\n",
    "]\n",
    "predicted = clf.predict(sentences)\n",
    "\n",
    "for s, p in zip(sentences, predicted):\n",
    "    print(u'The language of \"%s\" is \"%s\"' % (s, dataset.target_names[p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried changing the tolerance to a 1e-8, because that seemed like the only part of the program that I could try changing without breaking the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
